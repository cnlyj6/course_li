{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMvGLmFldANkFYlyrKBQ0Kf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Y7iVcCItYMha"},"outputs":[],"source":["import torch, sklearn, os\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n","import torch.nn as nn\n","import numpy as np\n","from tools import plot_training_loss, plot_training_acc\n","word2id_dict = {'UNK': 0}\n","idx = 1\n","max_len = 256\n","open(\"vocab.txt\", 'w').write('0' + \"\\t\" +\"UNK\" + \"\\n\")\n","def load_dataset(path):\n","    global idx\n","    example = []\n","    with open(path, \"r\", encoding=\"utf-8\") as fr:\n","        for line in fr:\n","            sentence_label = line.strip('\\n').strip().strip(\"\\t\").lower().split(\"\\t\")\n","            sentence = sentence_label[-1]\n","            label = 1 if int(\"\".join([c for c in sentence_label[0].split(\"_\")[1] if c.isdigit()])) >= 7 else 0\n","            sentence_encoded = []\n","            for token in sentence.split(\" \"):\n","                if token not in word2id_dict:\n","                    word2id_dict[token] = idx\n","                    open(\"vocab.txt\", 'a').write(str(idx) + \"\\t\" + token + \"\\n\")\n","                    idx += 1\n","                sentence_encoded.append(word2id_dict[token])\n","\n","            sentence_encoded = sentence_encoded[: max_len]\n","            sentence_encoded = sentence_encoded + [0] * (max_len - len(sentence_encoded))\n","            example.append([torch.Tensor(sentence_encoded), label])\n","\n","    return example\n","\n","\n","train_dataloader = torch.utils.data.DataLoader(load_dataset(\"./train.tsv\"), batch_size=128)\n","dev_dataloader = torch.utils.data.DataLoader(load_dataset(\"./dev.tsv\"), batch_size=128)\n","test_dataloader = torch.utils.data.DataLoader(load_dataset(\"./test.tsv\"), batch_size=128)\n","# print(train_dataloader)\n","\n","\n","class SentimentClassifier(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_embeddings, num_classes = 2, num_layers = 1, init_scale = 0.1, dropout_rate = None):\n","        super().__init__()\n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","        self.num_embeddings = num_embeddings\n","        self.num_classes = num_classes\n","        self.num_layers = num_layers\n","        self.init_scale = init_scale\n","        self.dropout_rate = dropout_rate\n","\n","        self.embedding = nn.Embedding(num_embeddings = num_embeddings, embedding_dim = input_size, max_norm=True)\n","\n","        self.dropout_layer = nn.Dropout(p=self.dropout_rate)\n","\n","        self.lstm_layer = nn.LSTM(input_size, hidden_size, num_layers)\n","\n","        self.cls_layer = nn.Linear(self.hidden_size, self.num_classes)\n","\n","    def forward(self, inputs):\n","        inputs = torch.tensor(inputs).to(torch.int64)\n","        inputs_emb = self.embedding(inputs)\n","        if self.dropout_rate is not None and self.dropout_rate > 0.0:\n","            inputs_emb = self.dropout_layer(inputs_emb)\n","        sequence_output, (hidden_states, cell_states) = self.lstm_layer(inputs_emb)\n","        hidden_states = hidden_states.squeeze(axis=0)\n","        logits = self.cls_layer(hidden_states)\n","        return logits\n","\n","num_epochs = 10\n","learning_rate = 0.0001\n","eval_steps = 50\n","log_steps = 10\n","save_dir = \"./checkpoints\"\n","\n","input_size = 256\n","hidden_size = 256\n","num_embeddings = len(word2id_dict)\n","num_layers = 1\n","dropout_rate = 0.2\n","num_classes = 2\n","model = SentimentClassifier(input_size, hidden_size, num_embeddings, num_classes=num_classes, num_layers=num_layers, dropout_rate=dropout_rate)\n","\n","optimizer = torch.optim.Adam(params = model.parameters(), lr=learning_rate)\n","\n","loss_fn = nn.CrossEntropyLoss()\n","def evaluate(model, data_loader):\n","    model.eval()\n","    for batch_id, data in enumerate(data_loader):\n","        inputs, labels = data\n","        logits = model(inputs.t())\n","        logits = np.argmax(logits.detach(), axis=1)\n","        accuracy = accuracy_score(labels.detach(), logits.detach())\n","        # precision, recall, f1, roc, auc1 = precision_score(labels.detach(), logits.detach()), recall_score(labels.detach(), logits.detach()), f1_score(labels, logits), roc_curve(labels, logits), auc(labels, logits)\n","    return accuracy\n","\n","def train(model):\n","    model.train()\n","    global_step = 0\n","    best_score = 0.\n","    train_loss_record = []\n","    train_score_record = []\n","    num_training_steps = len(train_dataloader) * num_epochs\n","    for epoch in range(num_epochs):\n","        for step, data in enumerate(train_dataloader):\n","            inputs, labels = data\n","            logits = model(inputs.t())\n","            logits = np.argmax(logits.detach(), axis=1)\n","            loss = loss_fn(logits.float(), labels.float())\n","            train_loss_record.append((global_step, loss.item()))\n","\n","            loss.requires_grad = True\n","\n","            loss.backward()\n","            optimizer.step()\n","            optimizer.zero_grad()\n","\n","            if global_step % log_steps == 0:\n","                print(f\"[Train] epoch: {epoch} / {num_epochs}, step: {global_step} / {num_training_steps}, loss: {loss.item():.5f}\")\n","\n","            if global_step != 0 and (global_step % eval_steps == 0 or global_step == (num_training_steps - 1)):\n","                accuracy = evaluate(model, dev_dataloader)\n","                train_score_record.append((global_step, accuracy))\n","                print(f\"[Evaluate] dev score: {accuracy:.5f}\")\n","                model.train()\n","\n","                if accuracy > best_score:\n","                    print(f\"[Evaluate] best accuracy performence has been updated: {best_score:.5f} --> {accuracy:.5f}\")\n","                    best_score = accuracy\n","\n","                    save_path = os.path.join(save_dir, \"best.pdparams\")\n","\n","                    torch.save(model.state_dict(), save_path)\n","\n","            global_step += 1\n","    save_path = os.path.join(save_dir, \"final.pdparams\")\n","    torch.save(model.state_dict(), save_path)\n","    print(f\"[Train] Training done!\")\n","\n","    return train_loss_record, train_score_record\n","train_loss_record, train_score_record = train(model)\n","\n","\n","plot_training_loss(train_loss_record, \"./images/chapter7_best_loss.pdf\", loss_legend_loc=\"upper right\", sample_step=60)\n","plot_training_acc(train_score_record, \"./images/chapter7_acc.pdf\", acc_legend_loc=\"lower right\", sample_step=1)\n","\n","saved_state = torch.load(\"./checkpoints/final.pdparams\")\n","\n","model_final = SentimentClassifier(input_size, hidden_size, num_embeddings, num_classes=num_classes, num_layers=num_layers, dropout_rate=dropout_rate)\n","\n","model_final.load_state_dict(saved_state)\n","accuracy = evaluate(model_final, test_dataloader)\n","print(f\"[Evaluate result] accuracy: {accuracy:.5f}\")\n","\n","\n","def infer(model, text):\n","    model.eval()\n","\n","    words = [word2id_dict.get(word, word2id_dict['UNK']) for word in text.split(\" \")]\n","\n","    words = torch.Tensor(words).to(torch.int64).unsqueeze(0)\n","\n","    logits = model(words)\n","\n","    id2label = {0: \"消极情绪\", 1: \"积极情绪\"}\n","\n","    max_label_id = np.argmax(logits.detach(), axis=1).numpy()[0]\n","\n","    pred_label = id2label[max_label_id]\n","\n","    print(\"Label: \", pred_label)\n","# text = \"The horrific production doesn't qualify as a \\\"film.\\\" It was obviously shot on video tape, and very poorly at that! There is a constant screaching sound for the audio(sounds like a bad microphone), which is so annoying that you sometimes cannot understand what the characters are saying. Badly dubbed-in music will suddenly appear in a scene, and the entire editing of this thing rates about a ZERO!<br /><br />The plot is contrived and ridiculous. A late 20's gay man trying to hide his live-in lover from parents visiting? PLEASE! And the reaction the mother has when she finds a picture of her son kissing his boyfrioend is beyond melodramatic and rolls right into stupid. Talk about a stereotypical view of gay life! The acting is worse than a porno movie, and the direction is very poor!<br /><br />As far as \\\"production\\\" goes, there isn't any!<br /><br />This title is simply a lame videotaped attempt to call itself a \\\"Film.\\\" There is no heart and soul to give it even the smallest bit of praise.<br /><br />It's just a stupid waste of time, so avoid it at all costs! BAD ACTING! BAD WRITING! BAD DIRECTING , and the title of \\\"producer\\\" is vanity as this trash probably costed them the price of the videotape they shot it on.<br /><br />This ametuer garbage has no business getting released onto a dvd as it's deceptive to the cunsomer. I cannot stress how horrible this \\\"SUGARPLUM\\\" crap is!<br /><br />\"\n","text = \"It's funny. It's not Arthur Miller or T.S. Elliot, but man this is funny. Kline and Fields are great.\"\n","infer(model, text)"]}]}